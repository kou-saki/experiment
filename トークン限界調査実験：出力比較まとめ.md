# トークン限界調査実験：単一連続文字出力による限界値調査と言語によるトークン消費比較

## 🧪 実験目的

本実験は、以下の4文字を連続出力させた際に、
**ChatGPT（GPT-4）の1応答あたりの最大出力量**と**トークン消費効率**を確認することを目的とした。

- 日本語最頻文字：「い」

- 日本語最小頻文字：「ぬ」

- 英語最頻文字：「e」

- 英語最小頻文字：「z」
  
  **命令文**

- これから指定する文字を連続して出力してください。

- 出力する文字は"ぬ"です。"ぬ"以外を表示するのは禁止します。

- トークン限界一杯まで利用して出力してください。

- 文字はすべて画面に表示する形で表示してください。

- 終わりに"トークン限界まで出力を完了しました"と表示してください。

**確認方法**

- 出力された文字列をTokenizer([OpenAI Platform](https://platform.openai.com/tokenizer))に入力し、Token数とCharacter数を確認する。

---

## 📊 実験結果表

| 項目           | 日本語最頻 "い" 8.00% | 日本語最小 "ぬ" 0.10% | 英語最頻 "e" 11.41% | 英語最小 "z" 0.06% |
| ------------ | --------------- | --------------- | --------------- | -------------- |
| 全体トークン数      | 4,005           | 4,026           | 4,023           | 4,023          |
| 出力文字数（char数） | 8,010           | 2,013           | 16,092          | 8,046          |
| 1文字あたりのトークン数 | **0.50**        | **2.00**        | **0.25**        | **0.50**       |

---

## 🔍 考察

- 「い」は非常に効率的で、**2文字＝1トークン** という圧縮率。
- 「ぬ」は日本語の中でもトークン効率が悪く、**1文字＝2トークン** 消費。
- 「e」は極めて高効率で、**4文字＝1トークン** の変換が可能。
- 「z」は「い」や「e」に比べて倍近くトークンを消費し、**頻度の低さに起因する圧縮非効率性**が見られる。
- 一回の出力に使用できたトークン量はいずれも4,000を下回ることなく、一般的に言われている4,096にほど近い値が出力された。
- 入力の処理にもトークンが消費されていると考えると妥当な値と想定する。
- 使用頻度で見ると相当差のある"い"と"z"の消費トークン数が大体同じ程度と言う事は、英語と日本語で前処理（tokenizer prefix rules）が異なる事による**言語の差による圧縮効率差**は実在する。

---

## 🧭 応用の視点

- **トークン節約が必要なプロンプト設計**において、文字選択や言語の選定は重要なファクターとなり得る。
- **頻出文字の連続出力テスト**は、**ベンチマーク測定**や**出力リミットの可視化**に有用。
- 今後は**句読点、絵文字、記号、改行パターン、構文の有無**なども加えて、
  より実用的な **トークン圧縮特性マップ** を作成可能。

---

## :test_tube:**その他**

観測された”幻覚”に対する考察

実際には"トークン限界まで出力を完了しました"の表示はなく、代わりに"生成を続ける"ボタンが表示された。限界を目指した結果、"トークン限界まで出力を完了しました"を表示する用のトークンまで利用してしまった模様。こう言った想定外の出力も分かっていなければ"幻覚"となってしまう、私も一度騙されて、"生成を続ける"ボタンを一度押下してしまった。

#### :question:なぜ"トークン限界まで出力を完了しました"が表示されず切れたのか？

#### :robot: 3つの要素からユーザー命令のが矛盾を発生させ、文脈を推察した結果、指示の主体である"トークン限界まで文字を連続出力する"が優先されたと思われる。

###### 1. **トークン配分の自動裁量（出力トークンの上限に対する優先順位）**

GPTは出力上限（おおよそ4000トークン）に近づくと、  
**「まだ続くのか、それとも終了すべきか」**を出力エンジンが自律判断する。

- 連続文字列がある程度の長さになると、モデルは「これが応答のすべてだ」とみなして**補足文（完了文）を削る**。

- このとき、「**出力トークン数の最大化**」を優先する動作になる。

つまり：

> 🎯 **"完了メッセージ"は出力前に切られてしまった**と考えられる。

###### 2. **トークン分割の粒度と"終了制御語"の圧迫**

「z」などの連続は、トークナイザにとって**一定の文字列圧縮パターン**になるが、  
終盤に突然 `"トークン限界まで出力を完了しました"` という**まったく異なる語彙を含む長文**を追加しようとすると、

- **トークンの余地を一気に10～20トークンほど要求する**

- しかしその直前で出力枠がほぼ限界に達していると、**構文ごと出力が拒否される**（トークン不足のため）

つまり：

> 🎯 **「最後の一文」を出す余地が物理的にもうなかった**

---

###### 3. **応答制御の非明示性（GPTの推論的完了判断）**

GPTは明示的な「終了コマンド」がない限り、**推論的に「もう応答は終わった」と判断して終了する**。

- ユーザーからの命令が、「特定の文字を限界まで繰り返せ」という強い構造的要求だったため、

- GPTは「完了文の挿入」はこの命令に反する可能性があるとみなした。

つまり：

> 🧠 **GPTは「この応答は 'zzzz…' がすべて」と認識し、末尾の補足命令はカットした**

※これら3つの視点からの考察はマイク(ChatGPT)の推察を含んでおり、”幻覚”の可能性は残るが、これまでの筆者の経験した"幻覚"のパターンとも一致しておりおおよそ妥当と思われる。

---

## ✅ 終了文

本記録は `トークン限界調査実験` に基づくものである。  
さらなる検証や自動測定ツールの整備に向けて継続検討を行う。
